{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the input string consist of n letters, a1... an.\n",
    "Let the grammar contain r terminal and nonterminal symbols R1... Rr. \n",
    "This grammar contains the subset Rs which is the set of start symbols.\n",
    "\n",
    "Let P[n,n,r] be an array of booleans. Initialize all elements of P to false. #dimensió de la matriu, amb tot a false\n",
    "\n",
    "For each i = 1 to n\n",
    "  For each unit production Rj → ai, set P[i,1,j] = true. #si la gramàtica pot generar els terminals, posar true\n",
    "\n",
    "For each i = 2 to n -- Length of string\n",
    "  For each j = 1 to n-i+1 -- Start of string\n",
    "    For each k = 1 to i-1 -- Partition of string\n",
    "      For each production RA -> RB RC\n",
    "        If P[j,k,B] and P[j+k,i-k,C] then set P[j,i,A] = true\n",
    "\n",
    "\n",
    "If any of P[1,n,x] is true (x is iterated over the set s, where s are all the indices for Rs)\n",
    "  Then string is member of language\n",
    "  Else string is not member of language"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S → a | XA | AX | b\n",
    "A → RB\n",
    "B → AX | b | a\n",
    "X → a\n",
    "R → XB\n",
    "\n",
    "heads ['S', 'A', 'B', 'X', 'R'], bodies [['a', 'XA', 'AX', 'b'], ['RB'], ['AX', 'b', 'a'], ['a'], ['XB']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AD'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = 'XAD'\n",
    "var[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_body = ['a', 'ε']\n",
    "current_body.remove('ε')\n",
    "current_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S', 'A', 'B', 'X', 'R']\n",
      "[['a', 'XA', 'AX', 'b'], ['RB'], ['AX', 'b', 'a'], ['a'], ['XB']]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "grammar = 'grammar1.txt'\n",
    "with open(grammar, 'r') as file:\n",
    "    # Read the contents of the file and save them as a class variable\n",
    "    contents = file.read()\n",
    "\n",
    "def replace_letter(bodies, letter_to_combine):\n",
    "    result = []\n",
    "    for body in bodies:\n",
    "        body = [letter for letter in body]\n",
    "        if all([letter!=letter_to_combine for letter in body]):\n",
    "            permutations = [''.join(body)]\n",
    "        elif body != [letter_to_combine,letter_to_combine]:           \n",
    "            permutations = []\n",
    "            for combination in [letter_to_combine,None]:\n",
    "                new_values = []\n",
    "                for value in body:\n",
    "                    if value == letter_to_combine: # If value is A (needs to be replaced)\n",
    "                        if combination != None: # If it is not empty string, subtitute A with body\n",
    "                            new_values.append(combination)   \n",
    "                    else: # If it is not A, add value\n",
    "                        new_values.append(value)\n",
    "                permutations.append(''.join(new_values))\n",
    "            else:\n",
    "                if combination != None:\n",
    "                    permutations.append(''.join(body))\n",
    "        else:\n",
    "            permutations = [letter_to_combine+letter_to_combine, letter_to_combine]\n",
    "        result += permutations\n",
    "    return result\n",
    "\n",
    "def convert_grammar(grammar, cnf = True):\n",
    "    \n",
    "    # Split the grammar string into separate lines\n",
    "    grammar_lines = grammar.strip().split('\\n')\n",
    "    heads, bodies = [], []\n",
    "    for rule_idx in range(len(grammar_lines)): # Process each line of the grammar\n",
    "        line = grammar_lines[rule_idx]\n",
    "        head, elements = line.split(' → ') # Splitting the line into the head and elements of the rule\n",
    "        values = elements.split(' | ') # Splitting the elements using \"|\" as the separator, for the cases of 'OR' statements\n",
    "        heads.append(head)\n",
    "        bodies.append(values)\n",
    "\n",
    "    print(heads)\n",
    "    print(bodies)\n",
    "    \n",
    "    if cnf:\n",
    "        alphabet = [letter for letter in string.ascii_uppercase if letter not in heads]\n",
    "        i = 0\n",
    "        while i < len(bodies):\n",
    "            for element in range(len(bodies[i])):\n",
    "                current_var = bodies[i][element]\n",
    "                #step 1:\n",
    "                ''' \n",
    "                Eliminate terminals from right side if they exist with other terminals or non-terminals\n",
    "                e.g: production rule X->xY can be decomposed as:\n",
    "                X->ZY\n",
    "                Z->x\n",
    "                '''\n",
    "                if any(char.islower() for char in current_var) and len(current_var) > 1:\n",
    "                    new_var = ''\n",
    "                    for letter in range(len(current_var)):\n",
    "                        if current_var[letter].islower():\n",
    "                            new_letter = alphabet.pop(0)\n",
    "                            heads.append(new_letter)\n",
    "                            bodies.append([current_var[letter]])\n",
    "                            new_var += new_letter\n",
    "                        else:\n",
    "                            new_var += current_var[letter]\n",
    "                    bodies[i][element] = new_var\n",
    "                \n",
    "                current_var = bodies[i][element] #in case something has changed\n",
    "                \n",
    "                #step 2:\n",
    "                '''\n",
    "                Eliminate RHS with more than two non-terminals.\n",
    "                e.g,; production rule X->LYZ can be decomposed as:\n",
    "                X->LP\n",
    "                P->YZ\n",
    "                '''\n",
    "                if len(current_var) > 2:\n",
    "                    new_letter = alphabet.pop(0)\n",
    "                    new_var = current_var[0] + new_letter #Change to two terminals\n",
    "                    bodies[i][element] = new_var #change the body of the rule to a two terminals rule\n",
    "                    heads.append(new_letter) #add new created rule to heads\n",
    "                    bodies.append([current_var[1:]]) #add new rule (the rest of the body of the original one) to bodies \n",
    "                \n",
    "                current_var = bodies[i][element] #in case something has changed    \n",
    "            i+=1\n",
    "\n",
    "\n",
    "        #step 3:\n",
    "        '''\n",
    "        Eliminate ε-rules\n",
    "        e.g: a production rule can derive is nullable in two scenarios:\n",
    "            - ε appears explicitly: A → ε or  A → a | ε \n",
    "            - the rule is implicitly nullable: A → B where B doesn't exist\n",
    "        For purely nullable rules: all istances of the head are deleted\n",
    "        For partially nullable rules: consider that all appearances of the rule as possible empty string \n",
    "        '''\n",
    "        #Dealing with implicitly nullable rules A → B\n",
    "        for body in range(len(bodies)):\n",
    "            current_body = bodies[body]\n",
    "            if 'ε' in current_body or ((len(current_body) == 1) and (current_body[0].isupper() and (len(current_body[0])==1)) ): # Rule is nullable\n",
    "                if len(current_body) == 1 and current_body != 'ε': \n",
    "                    current_body == 'ε'\n",
    "                    bodies[body][element] = 'ε' #we delete A → B\n",
    "        \n",
    "        #dealing with explicitly pure nullable rule A → ε\n",
    "        for body in range(len(bodies)): \n",
    "            current_body = bodies[body]\n",
    "            if 'ε' in current_body and len(current_body)==1:\n",
    "                to_delete = heads[body] #Rule that should be deleted from other rules\n",
    "                for rule in range(len(bodies)):\n",
    "                    if bodies[rule]:\n",
    "                        updated_rule = [element.replace(to_delete, '') for element in bodies[rule]] #delete all the heads appearences in each rule\n",
    "                        bodies[rule] = updated_rule\n",
    "                heads[body] = False\n",
    "                bodies[body] = False\n",
    "        \n",
    "        #updating lists to delete the null rules\n",
    "        bodies = [element for element in bodies if element != False]\n",
    "        heads = [element for element in heads if element != False]\n",
    "\n",
    "        #dealing with explicitly impure nullable rule A → a | ε \n",
    "        for body in range(len(bodies)):\n",
    "            current_body = bodies[body]\n",
    "            if len(current_body) > 1 and 'ε' in current_body: \n",
    "                current_body.remove('ε') #elements for the permutation\n",
    "                bodies[body] = current_body #we update the rule so it doesn't have ε \n",
    "                #modify the production rules:\n",
    "                null_head = heads[body]\n",
    "                nulled_bodies = [] #list of bodies that contain the nullable rule\n",
    "                for body2 in range(len(bodies)): #we find the heads of the elements that contain the nullable rule\n",
    "                    for element in range(len(bodies[body2])):\n",
    "                        if null_head in bodies[body2][element]: #if the nullable rule appears in some other rule\n",
    "                            nulled_bodies.append(heads[body2]) \n",
    "                for nulled in nulled_bodies: #3.1 i 3.2\n",
    "                    nulled_index = heads.index(nulled)\n",
    "                    new_bodies = replace_letter(bodies[nulled_index], null_head)\n",
    "                    bodies[nulled_index] = new_bodies\n",
    "                    changed_rule = heads[nulled_index]\n",
    "                    for body3 in range(len(bodies)):\n",
    "                        if any(changed_rule in el for el in bodies[body3]):\n",
    "                            new_bodies = replace_letter(bodies[body3], changed_rule)\n",
    "                            bodies[body3] = new_bodies\n",
    "\n",
    "        #step 4:\n",
    "        '''\n",
    "        Eliminate unit rules\n",
    "        e.g: considering production rule A → B:\n",
    "            if B → CD exists, original rule should be converted to  A → CD\n",
    "        '''\n",
    "        for body in range(len(bodies)):\n",
    "            current_body = bodies[body]\n",
    "            if ((len(current_body) == 1) and (current_body[0].isupper() and (len(current_body[0])==1)) ): # Rule is unitary\n",
    "                if heads.index(bodies[body]):\n",
    "                    actual_rule = bodies[heads.index(bodies[body])] #he look for B → CD, specifically CD\n",
    "                    bodies[body] = actual_rule\n",
    "        \n",
    "        #step 5:\n",
    "        '''\n",
    "        Filter unitary rules that are left\n",
    "        '''\n",
    "        bodies = [[item for item in sublist if not (len(item) == 1 and item.isupper())] for sublist in bodies]\n",
    "\n",
    "\n",
    "                       \n",
    "             \n",
    "    #encoding the rules: each rule name will be encoded with a number from 0 to the amount of rules-1\n",
    "    encoding_dict, encoding = {}, 0 # Creating an empty dictionary to store the rules and initializing the encoding\n",
    "    for line in range(len(heads)):\n",
    "        encoding_dict[heads[line]] = encoding\n",
    "        encoding += 1\n",
    "            \n",
    "    #Creating a list for each type of rule (terminal and non-terminal). The index states the head code and the content its body\n",
    "    ter_rules, nter_rules = [[] for _ in range(encoding)], [[] for _ in range(encoding)]\n",
    "    for head,body in zip(heads, bodies): # Process each line of the grammar\n",
    "        for element in body: \n",
    "            if element.isupper(): #it's a non-terminal\n",
    "                #Creating a tuple so that 'AB' ~ ('A','B'), for future implementation use\n",
    "                tuple_form = (encoding_dict[element[0]],encoding_dict[element[1]]) \n",
    "                nter_rules[encoding_dict[head]].append(tuple_form)\n",
    "            else: #is a terminal\n",
    "                ter_rules[encoding_dict[head]].append(element)\n",
    "\n",
    "    return ter_rules, nter_rules\n",
    "\n",
    "t_rules, nt_rules = convert_grammar(contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [], ['b'], ['a', 'b'], ['d', 'ε']]\n"
     ]
    }
   ],
   "source": [
    "grammar = 'grammar1.txt'\n",
    "with open(grammar, 'r') as file:\n",
    "    # Read the contents of the file and save them as a class variable\n",
    "    contents = file.read()\n",
    "\n",
    "\n",
    "\n",
    "def convert_grammar(grammar, cnf = True):\n",
    "    \n",
    "    # Split the grammar string into separate lines\n",
    "    grammar_lines = grammar.strip().split('\\n')\n",
    "    \n",
    "    rules = [[] for _ in range(len(grammar_lines))] #original length is the amount of rules\n",
    "    \n",
    "    #encoding the rules: each rule name will be encoded with a number from 0 to the amount of rules-1\n",
    "    encoding_dict, encoding = {}, 0 # Creating an empty dictionary to store the rules and initializing the encoding\n",
    "    for line in range(len(grammar_lines)):\n",
    "        encoding_dict[grammar_lines[line][0]] = encoding\n",
    "        encoding += 1\n",
    "\n",
    "    #Creating a list for each type of rule (terminal and non-terminal). The index states the head code and the content its body\n",
    "    t_rules, nt_rules = [[] for _ in range(encoding)], [[] for _ in range(encoding)]\n",
    "    \n",
    "    for line in grammar_lines: # Process each line of the grammar\n",
    "        head, elements = line.split(' → ') # Splitting the line into the head and elements of the rule\n",
    "        values = elements.split(' | ') # Splitting the elements using \"|\" as the separator, for the cases of 'OR' statements\n",
    "        for element in values: \n",
    "            if len(element) > 2: #The rule is not found in Chomsky Natural Form\n",
    "                rules_to_create = len(element)-1 #we have to create some we rules, 1 less than tha amount of non-terminals\n",
    "                encoding_dict['X'+encoding] = encoding\n",
    "\n",
    "            if element.isupper(): #it's a non-terminal\n",
    "                #Creating a tuple so that 'AB' ~ ('A','B'), for future implementation use\n",
    "                tuple_form = (encoding_dict[element[0]],encoding_dict[element[1]]) \n",
    "                nt_rules[encoding_dict[head]].append(tuple_form)\n",
    "            else: #is a terminal\n",
    "                t_rules[encoding_dict[head]].append(element)\n",
    "    print(t_rules)\n",
    "\n",
    "convert_grammar(contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nS → a | XA | AX | b\\nA → RB\\nB → AX | b | a\\nX → a\\nR → XB'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar = 'grammar1.txt'\n",
    "with open(grammar, 'r') as file:\n",
    "    # Read the contents of the file and save them as a class variable\n",
    "    contents = file.read()\n",
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNF(grammar):\n",
    "    \n",
    "    pass\n",
    "\n",
    "grammar = 'grammar1.txt'\n",
    "with open(grammar, 'r') as file:\n",
    "    # Read the contents of the file and save them as a class variable\n",
    "    contents = file.read()\n",
    "CNF(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "class Dynamic_CKY:\n",
    "    \n",
    "    def __init__(self, rules, grammar):\n",
    "        self.grammar = grammar\n",
    "        self.rules = rules\n",
    "        self.amount_rules = 5\n",
    "\n",
    "    def read_file(self):\n",
    "        '''\n",
    "        This function is used to read a '.txt' file containing the rules of a certain grammar.\n",
    "        '''\n",
    "        # Open the file in read mode using the file name\n",
    "        with open(self.grammar, 'r') as file:\n",
    "            # Read the contents of the file and save them as a class variable\n",
    "            contents = file.read()\n",
    "            return contents\n",
    "\n",
    "    def convert_grammar(self):\n",
    "        ''' \n",
    "        Converts the grammar rules into the format the class works with.\n",
    "        Args:\n",
    "            self.contents('.txt' file): grammar rules \n",
    "        Generates:\n",
    "            encoding_dict(dictionary): Encoding used for the rules, where the key is the head of the rule and the body is the numerical encoding used.\n",
    "            self.t_rules(list): Grammar rules, considering only the ones that derive terminals. \n",
    "            self.nt_rules(list): Grammar rules, considering only the ones that derive non-terminals.\n",
    "        '''\n",
    "        grammar = self.read_file() #Reading the grammar file\n",
    "        # Split the grammar string into separate lines\n",
    "        grammar_lines = grammar.strip().split('\\n')\n",
    "        #encoding the rules: each rule name will be encoded with a number from 0 to the amount of rules-1\n",
    "        self.encoding_dict, encoding = {}, 0 # Creating an empty dictionary to store the rules and initializing the encoding\n",
    "        for line in range(len(grammar_lines)):\n",
    "            self.encoding_dict[grammar_lines[line][0]] = encoding\n",
    "            encoding += 1\n",
    "        #Creating a list for each type of rule (terminal and non-terminal). The index states the head code and the content its body\n",
    "        self.t_rules, self.nt_rules = [[] for _ in range(encoding)], [[] for _ in range(encoding)]\n",
    "        for line in grammar_lines: # Process each line of the grammar\n",
    "            head, elements = line.split(' → ') # Splitting the line into the head and elements of the rule\n",
    "            values = elements.split(' | ') # Splitting the elements using \"|\" as the separator, for the cases of 'OR' statements\n",
    "            for element in values: \n",
    "                if element.isupper(): #it's a non-terminal\n",
    "                    #Creating a tuple so that 'AB' ~ ('A','B'), for future implementation use\n",
    "                    tuple_form = (self.encoding_dict[element[0]],self.encoding_dict[element[1]]) \n",
    "                    self.nt_rules[self.encoding_dict[head]].append(tuple_form)\n",
    "                else: #is a terminal\n",
    "                    self.t_rules[self.encoding_dict[head]].append(element)\n",
    "    \n",
    "    def test_word(self, word):\n",
    "        ''' \n",
    "        Tests a certain word for the processed grammar.\n",
    "        Input:\n",
    "            word(string): The word to check by the CKY.\n",
    "        Returns:\n",
    "            boolean: True or False according to belonging to the grammar.\n",
    "        Example:\n",
    "            >>> cky = Dynamic_CKY(grammar)\n",
    "            >>> cky.test_word('aabab')\n",
    "            True\n",
    "        '''\n",
    "        self.word = word\n",
    "        self.length = len(word)\n",
    "        self.build_table()\n",
    "        \n",
    "    def build_table(self):\n",
    "        '''\n",
    "        Builds the table for the dynamic programming version of the CKY.\n",
    "        Input:\n",
    "            self.contents('.txt' file): Grammar rules.\n",
    "            self.word(string): The word to check by the CKY. \n",
    "        Returns:\n",
    "            self.table(list): Table with the derivation rules of the given word for the corresponding grammar.\n",
    "        '''\n",
    "        self.table = [[set() for p in range(self.length)]for i in range(self.length)]\n",
    "        # We make sure the grammar can generate the terminals\n",
    "        for terminal in range(self.length):\n",
    "            self.table[self.length-1][terminal] = self.rules[word[terminal]]\n",
    "        for i in range(self.length-2,-1, -1): # fila\n",
    "            for j in range(0,i+1,1): # columna\n",
    "                i1, j1 = self.length-1, j\n",
    "                i2, j2 = i+1, j+1\n",
    "                while i1 > i:\n",
    "                    # Fer combinacions\n",
    "                    for combi in self.combination((i1,j1),(i2,j2)):\n",
    "                        if combi in rules:\n",
    "                            if (rules[combi]) == 1: self.table[i][j].add(rules[combi]) \n",
    "                            else : self.table[i][j].update(rules[combi]) \n",
    "                    i1, i2, j2 = i1-1, i2+1, j2+1 \n",
    "  \n",
    "    def combination(self, cell1, cell2):\n",
    "        return list(product(self.table[cell1[0]][cell1[1]], self.table[cell2[0]][cell2[1]]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = 'grammar1.txt'\n",
    "cky = Dynamic_CKY(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['DD', '']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_letter(bodies, letter_to_combine):\n",
    "    result = []\n",
    "    for body in bodies:\n",
    "        body = [letter for letter in body]\n",
    "        permutations = []\n",
    "        for combination in [letter_to_combine,None]:\n",
    "            print(combination)\n",
    "            new_values = []\n",
    "            amount = sum([letter == letter_to_combine for letter in body])\n",
    "            for i in amount:\n",
    "                for value in body:\n",
    "                    if value == letter_to_combine: # If value is A (needs to be replaced)\n",
    "                        if combination != None: # If it is not empty string, subtitute A with body\n",
    "                            new_values.append(combination)   \n",
    "                    else: # If it is not A, add value\n",
    "                        new_values.append(value)\n",
    "                permutations.append(''.join(new_values))\n",
    "            else:\n",
    "                if combination != None:\n",
    "                    permutations.append(''.join(body))\n",
    "        result += permutations\n",
    "    return result\n",
    "replace_letter(['DD'],'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practicapaa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
