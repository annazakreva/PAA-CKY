{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the input string consist of n letters, a1... an.\n",
    "Let the grammar contain r terminal and nonterminal symbols R1... Rr. \n",
    "This grammar contains the subset Rs which is the set of start symbols.\n",
    "\n",
    "Let P[n,n,r] be an array of booleans. Initialize all elements of P to false. #dimensió de la matriu, amb tot a false\n",
    "\n",
    "For each i = 1 to n\n",
    "  For each unit production Rj → ai, set P[i,1,j] = true. #si la gramàtica pot generar els terminals, posar true\n",
    "\n",
    "For each i = 2 to n -- Length of string\n",
    "  For each j = 1 to n-i+1 -- Start of string\n",
    "    For each k = 1 to i-1 -- Partition of string\n",
    "      For each production RA -> RB RC\n",
    "        If P[j,k,B] and P[j+k,i-k,C] then set P[j,i,A] = true\n",
    "\n",
    "\n",
    "If any of P[1,n,x] is true (x is iterated over the set s, where s are all the indices for Rs)\n",
    "  Then string is member of language\n",
    "  Else string is not member of language"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S → a | XA | AX | b\n",
    "A → RB\n",
    "B → AX | b | a\n",
    "X → a\n",
    "R → XB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'b'], [], ['b', 'a'], ['a'], []]\n",
      "[[(3, 1), (1, 3)], [(4, 2)], [(1, 3)], [], [(3, 2)]]\n",
      "{'S': 0, 'A': 1, 'B': 2, 'X': 3, 'R': 4}\n"
     ]
    }
   ],
   "source": [
    "grammar = 'grammar1.txt'\n",
    "with open(grammar, 'r') as file:\n",
    "    # Read the contents of the file and save them as a class variable\n",
    "    contents = file.read()\n",
    "\n",
    "def convert_grammar(grammar):\n",
    "    # Split the grammar string into separate lines\n",
    "    grammar_lines = grammar.strip().split('\\n')\n",
    "    #encoding the rules: each rule name will be encoded with a number from 0 to the amount of rules-1\n",
    "    encoding_dict, encoding = {}, 0 # Creating an empty dictionary to store the rules and initializing the encoding\n",
    "    for line in range(len(grammar_lines)):\n",
    "        encoding_dict[grammar_lines[line][0]] = encoding\n",
    "        encoding += 1\n",
    "    #Creating a list for each type of rule (terminal and non-terminal). The index states the head code and the content its body\n",
    "    t_rules, nt_rules = [[] for _ in range(encoding)], [[] for _ in range(encoding)]\n",
    "    for line in grammar_lines: # Process each line of the grammar\n",
    "        head, elements = line.split(' → ') # Splitting the line into the head and elements of the rule\n",
    "        values = elements.split(' | ') # Splitting the elements using \"|\" as the separator, for the cases of 'OR' statements\n",
    "        for element in values: \n",
    "            if element.isupper(): #it's a non-terminal\n",
    "                #Creating a tuple so that 'AB' ~ ('A','B'), for future implementation use\n",
    "                tuple_form = (encoding_dict[element[0]],encoding_dict[element[1]]) \n",
    "                nt_rules[encoding_dict[head]].append(tuple_form)\n",
    "            else: #is a terminal\n",
    "                t_rules[encoding_dict[head]].append(element)\n",
    "    print(t_rules)\n",
    "    print(nt_rules)\n",
    "    print(encoding_dict)\n",
    "\n",
    "convert_grammar(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S → a | XA | AX | b\n",
      "A → RB\n",
      "B → AX | b | a\n",
      "X → a\n",
      "R → XB\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "class Dynamic_CKY:\n",
    "    \n",
    "    def __init__(self, rules, grammar):\n",
    "        self.grammar = grammar\n",
    "        self.rules = rules\n",
    "        self.amount_rules = 5\n",
    "\n",
    "    def read_file(self):\n",
    "        '''\n",
    "        This function is used to read a '.txt' file containing the rules of a certain grammar.\n",
    "        '''\n",
    "        # Open the file in read mode using the file name\n",
    "        with open(self.grammar, 'r') as file:\n",
    "            # Read the contents of the file and save them as a class variable\n",
    "            contents = file.read()\n",
    "            return contents\n",
    "\n",
    "    def convert_grammar(self):\n",
    "        ''' \n",
    "        Converts the grammar rules into the format the class works with.\n",
    "        Args:\n",
    "            self.contents('.txt' file): grammar rules \n",
    "        Generates:\n",
    "            encoding_dict(dictionary): Encoding used for the rules, where the key is the head of the rule and the body is the numerical encoding used.\n",
    "            self.t_rules(list): Grammar rules, considering only the ones that derive terminals. \n",
    "            self.nt_rules(list): Grammar rules, considering only the ones that derive non-terminals.\n",
    "        '''\n",
    "        grammar = self.read_file() #Reading the grammar file\n",
    "        # Split the grammar string into separate lines\n",
    "        grammar_lines = grammar.strip().split('\\n')\n",
    "        #encoding the rules: each rule name will be encoded with a number from 0 to the amount of rules-1\n",
    "        self.encoding_dict, encoding = {}, 0 # Creating an empty dictionary to store the rules and initializing the encoding\n",
    "        for line in range(len(grammar_lines)):\n",
    "            self.encoding_dict[grammar_lines[line][0]] = encoding\n",
    "            encoding += 1\n",
    "        #Creating a list for each type of rule (terminal and non-terminal). The index states the head code and the content its body\n",
    "        self.t_rules, self.nt_rules = [[] for _ in range(encoding)], [[] for _ in range(encoding)]\n",
    "        for line in grammar_lines: # Process each line of the grammar\n",
    "            head, elements = line.split(' → ') # Splitting the line into the head and elements of the rule\n",
    "            values = elements.split(' | ') # Splitting the elements using \"|\" as the separator, for the cases of 'OR' statements\n",
    "            for element in values: \n",
    "                if element.isupper(): #it's a non-terminal\n",
    "                    #Creating a tuple so that 'AB' ~ ('A','B'), for future implementation use\n",
    "                    tuple_form = (self.encoding_dict[element[0]],self.encoding_dict[element[1]]) \n",
    "                    self.nt_rules[self.encoding_dict[head]].append(tuple_form)\n",
    "                else: #is a terminal\n",
    "                    self.t_rules[self.encoding_dict[head]].append(element)\n",
    "    \n",
    "    def test_word(self, word):\n",
    "        ''' \n",
    "        Tests a certain word for the processed grammar.\n",
    "        Input:\n",
    "            word(string): The word to check by the CKY.\n",
    "        Returns:\n",
    "            boolean: True or False according to belonging to the grammar.\n",
    "        Example:\n",
    "            >>> cky = Dynamic_CKY(grammar)\n",
    "            >>> cky.test_word('aabab')\n",
    "            True\n",
    "        '''\n",
    "        self.word = word\n",
    "        self.length = len(word)\n",
    "        self.build_table()\n",
    "        \n",
    "    def build_table(self):\n",
    "        '''\n",
    "        Builds the table for the dynamic programming version of the CKY.\n",
    "        Input:\n",
    "            self.contents('.txt' file): Grammar rules.\n",
    "            self.word(string): The word to check by the CKY. \n",
    "        Returns:\n",
    "            self.table(list): Table with the derivation rules of the given word for the corresponding grammar.\n",
    "        '''\n",
    "        self.table = [[set() for p in range(self.length)]for i in range(self.length)]\n",
    "        # We make sure the grammar can generate the terminals\n",
    "        for terminal in range(self.length):\n",
    "            self.table[self.length-1][terminal] = self.rules[word[terminal]]\n",
    "        for i in range(self.length-2,-1, -1): # fila\n",
    "            for j in range(0,i+1,1): # columna\n",
    "                i1, j1 = self.length-1, j\n",
    "                i2, j2 = i+1, j+1\n",
    "                while i1 > i:\n",
    "                    # Fer combinacions\n",
    "                    for combi in self.combination((i1,j1),(i2,j2)):\n",
    "                        if combi in rules:\n",
    "                            if (rules[combi]) == 1: self.table[i][j].add(rules[combi]) \n",
    "                            else : self.table[i][j].update(rules[combi]) \n",
    "                    i1, i2, j2 = i1-1, i2+1, j2+1 \n",
    "  \n",
    "    def combination(self, cell1, cell2):\n",
    "        return list(product(self.table[cell1[0]][cell1[1]], self.table[cell2[0]][cell2[1]]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = 'grammar1.txt'\n",
    "cky = Dynamic_CKY(grammar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practicapaa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
